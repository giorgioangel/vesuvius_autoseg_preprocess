{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cucim.skimage.segmentation import checkerboard_level_set, morphological_chan_vese # works only with cupy 12.3.0\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Manager, Process, Queue, Value, Lock\n",
    "import blosc2\n",
    "import os\n",
    "from time import sleep\n",
    "from utils import load_tifstack, chunk_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 8\n",
    "# Create a queue for each GPU using Queue for multiprocessing\n",
    "gpu_queues = [Queue() for _ in range(num_gpus)]\n",
    "manager_acwe = Manager()\n",
    "acwe_dict = manager_acwe.dict()\n",
    "lock = Lock()\n",
    "total_chunks = Value('i', 0)\n",
    "processed_chunks = Value('i', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producer function to assign chunks to GPU queues dynamically\n",
    "def producer(scroll, folder_path, chunk_size, gpu_queues, total_chunks):\n",
    "    for i, (z, y, x) in tqdm(enumerate(chunk_generator(scroll.shape, chunk_size))):\n",
    "        filepath = os.path.join(folder_path, f\"chunk_z_y_x_{z}_{y}_{x}.b2nd\")\n",
    "        gpu_id = i % num_gpus\n",
    "        chunk = blosc2.open(filepath, mode=\"r\")[:,:,:].astype(np.float32)\n",
    "        chunk_id = (z, y, x)\n",
    "        gpu_queues[gpu_id].put((chunk_id, chunk))\n",
    "        with lock:\n",
    "            total_chunks.value += 1\n",
    "        delta = total_chunks.value - processed_chunks.value\n",
    "        sleep(20*(delta//8))\n",
    "    # Signal the end of the data with a special value (None)\n",
    "    for gpu_queue in gpu_queues:\n",
    "        gpu_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer function to process chunks on GPU\n",
    "def process_chunk_on_gpu(gpu_id, task_queue, dict, processed_chunk, lock):\n",
    "    cp.cuda.Device(gpu_id).use()\n",
    "    while True:\n",
    "        item = task_queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        chunk_id, chunk = item\n",
    "        chunk = cp.asarray(chunk)\n",
    "\n",
    "        chunk /= 65535.\n",
    "\n",
    "        init_ls = checkerboard_level_set(chunk.shape, 5)\n",
    "        #print(\"ok\", gpu_id)\n",
    "        #print(\"Before morpho\", chunk.shape)\n",
    "        mask = morphological_chan_vese(image=chunk, num_iter=20, init_level_set=init_ls)\n",
    "        #print(\"chanvese\", gpu_id)\n",
    "        average_1 = cp.mean(chunk[mask == 1])\n",
    "        average_2 = cp.mean(chunk[mask == 0])\n",
    "\n",
    "        if average_2 > average_1:\n",
    "            cp.invert(mask, out=mask)\n",
    "        \n",
    "        with lock:\n",
    "            dict[chunk_id] = mask.get().astype(np.uint8)\n",
    "            processed_chunk.value += 1\n",
    "\n",
    "        del init_ls, chunk, mask\n",
    "        #free_memory()\n",
    "        #cp.cuda.Stream.null.synchronize()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_mask_process(output_folder, chunk_size, dict, total_chunks, processed_chunks):\n",
    "    clevel = 9\n",
    "    nthreads = 200\n",
    "    cparams = {\n",
    "            \"codec\": blosc2.Codec.ZSTD,\n",
    "            \"clevel\": clevel,\n",
    "            \"filters\": [blosc2.Filter.BITSHUFFLE, blosc2.Filter.BYTEDELTA],\n",
    "            \"filters_meta\": [0, 0],\n",
    "            \"nthreads\": nthreads,\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        if processed_chunks.value == total_chunks.value and len(dict) == 0:\n",
    "            break\n",
    "        for chunk_id, mask in list(dict.items()):\n",
    "            z, y, x = chunk_id\n",
    "            filepath = os.path.join(output_folder, f\"chunk_z_y_x_{z}_{y}_{x}.b2nd\")\n",
    "            try:\n",
    "                mask_array = blosc2.empty(mask.shape, dtype=np.uint8, chunks=(chunk_size[0],chunk_size[1],chunk_size[2]), blocks=(100,100,100), urlpath=filepath, cparams=cparams)\n",
    "                mask_array[:,:,:] = mask\n",
    "                #print(f\"Writer: Finished writing chunk {chunk_id}\")\n",
    "            except:\n",
    "                continue\n",
    "            del dict[chunk_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll = load_tifstack(\"../Scroll2.volpkg/volumes/20230210143520_grids\")\n",
    "chunk_size = [800, 800, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start a producer process\n",
    "producer_process = Process(target=producer, args=(scroll, \"./scroll2-denoised\", chunk_size, gpu_queues, total_chunks))\n",
    "producer_process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start a process for each GPU (right now on CPU)\n",
    "processes = []\n",
    "for gpu_id in range(num_gpus):\n",
    "    p = Process(target=process_chunk_on_gpu, args=(gpu_id, gpu_queues[gpu_id], acwe_dict, processed_chunks, lock))\n",
    "    processes.append(p)\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start the writer process\n",
    "mwriter = Process(target=writer_mask_process, args=(\"./scroll2-denoised/mask\", chunk_size, acwe_dict, total_chunks, processed_chunks))\n",
    "mwriter.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_process.close()\n",
    "for p in processes:\n",
    "    p.close()\n",
    "mwriter.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
